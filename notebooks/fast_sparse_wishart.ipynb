{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast sparse wishart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By `@jhmarcus`\n",
    "\n",
    "Here I explore taking advantage the sparsity of the laplacian matrix (the precision matrix in the IBR model) to compute the log density of the Wishart distribution. `julia` seems to have nice linear algebra support for computing sparse cholesky decompositions which is exactly what we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the `scipy.stats` implementation ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "        log_det_x = np.zeros(x.shape[-1])\n",
    "        scale_inv_x = np.zeros(x.shape)\n",
    "        tr_scale_inv_x = np.zeros(x.shape[-1])\n",
    "        for i in range(x.shape[-1]):\n",
    "            _, log_det_x[i] = self._cholesky_logdet(x[:,:,i])\n",
    "            scale_inv_x[:,:,i] = scipy.linalg.cho_solve((C, True), x[:,:,i])\n",
    "            tr_scale_inv_x[i] = scale_inv_x[:,:,i].trace()\n",
    "\n",
    "        # Log PDF\n",
    "        out = ((0.5 * (df - dim - 1) * log_det_x - 0.5 * tr_scale_inv_x) -\n",
    "               (0.5 * df * dim * _LOG_2 + 0.5 * df * log_det_scale +\n",
    "                multigammaln(0.5*df, dim)))\n",
    "\n",
    "```\n",
    "\n",
    "Let $\\mathbf{S}$ be the sample covariance matrix and $\\mathbf{\\Lambda}$ be the precision matrix i.e. $\\mathbf{\\Lambda} = \\mathbf{\\Sigma}^{-1}$. We can see the most expensive computations are computing ...\n",
    "\n",
    "* $|\\mathbf{S}|$ which is only computed once \n",
    "* $|\\mathbf{\\Lambda}^{-1}| = \\frac{1}{|\\mathbf{\\Lambda}|}$ which computed each iteration of mcmc or optimization\n",
    "\n",
    "Note that $\\mathbf{S}$ is not sparse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports / Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(UInt32[0x000007c6], Base.dSFMT.DSFMT_state(Int32[-863370057, 1073434926, 174807504, 1073178214, 1034078006, 1073367208, -450309519, 1073714622, -24949693, 1073723854  …  1357943618, 1073343485, 520554461, 1072703876, 231516093, -1022460827, -640665436, -1160497238, 382, 0]), [1.95522, 1.46572, 1.97599, 1.41763, 1.00167, 1.23093, 1.10771, 1.07047, 1.60926, 1.71768  …  1.96975, 1.25279, 1.88343, 1.84652, 1.52945, 1.68392, 1.0424, 1.92873, 1.41223, 1.61294], 382)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "using LightGraphs\n",
    "\n",
    "# set seed \n",
    "srand(1990) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the precision matrix as the graph laplacian of a simple square grid ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000×40000 SparseMatrixCSC{Int64,Int64} with 516004 stored entries:\n",
       "  [1    ,     1]  =  6\n",
       "  [2    ,     1]  =  -5\n",
       "  [3    ,     1]  =  1\n",
       "  [201  ,     1]  =  -5\n",
       "  [202  ,     1]  =  2\n",
       "  [401  ,     1]  =  1\n",
       "  [1    ,     2]  =  -5\n",
       "  [2    ,     2]  =  12\n",
       "  [3    ,     2]  =  -6\n",
       "  [4    ,     2]  =  1\n",
       "  ⋮\n",
       "  [39800, 39999]  =  2\n",
       "  [39997, 39999]  =  1\n",
       "  [39998, 39999]  =  -6\n",
       "  [39999, 39999]  =  12\n",
       "  [40000, 39999]  =  -5\n",
       "  [39600, 40000]  =  1\n",
       "  [39799, 40000]  =  2\n",
       "  [39800, 40000]  =  -5\n",
       "  [39998, 40000]  =  1\n",
       "  [39999, 40000]  =  -5\n",
       "  [40000, 40000]  =  6"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_row = 200 # number of rows in grid\n",
    "n_col = 200 # number of cols in grid\n",
    "n = n_row * n_col # total number of nodes\n",
    "G = Grid([n_row, n_col]) # create the grid\n",
    "Q = laplacian_matrix(G) # compute graph laplacian\n",
    "QQt = Q * Q' # Using the Hanks 2016 precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.401222 seconds (63 allocations: 82.157 MiB, 0.98% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92575.73400504058"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time begin\n",
    "    F = cholfact(QQt) # do sparse cholesky factorization\n",
    "    d = logdet(F) # compute logdet of QQt\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems pretty fast for a covariance of dimension ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 40000)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(QQt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when I tried this in python using the naive `np.linalg.chol` on a laplacian stored as a dense matrix it failed and it doesn't look like there is support for cholesky factorization of sparse matrices using `scipy.sparse`. The `R` `Matrix` library looks interesting to explore more as wraps the same `CHOLMOD` library"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
